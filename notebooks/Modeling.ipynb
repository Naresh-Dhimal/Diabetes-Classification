{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c73cd05-0a99-4719-8be8-2c8e18d97023",
   "metadata": {},
   "source": [
    "# Features Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15287caa-b4c0-4ca1-a3e5-cbd155bab6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the important libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Evalution\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Serialization\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5473b0d8-8d97-4fd3-85da-1aefc3118f2d",
   "metadata": {},
   "source": [
    "### Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27850e94-ee6d-484d-9dc7-bdaea07ea355",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './notebooks/cleaned_dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m dataset_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./notebooks/cleaned_dataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# importing dataset and converting data into pandas dataframe\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './notebooks/cleaned_dataset.csv'"
     ]
    }
   ],
   "source": [
    "# dataset path\n",
    "dataset_path = \"./notebooks/cleaned_dataset.csv\"\n",
    "\n",
    "# importing dataset and converting data into pandas dataframe\n",
    "df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedbc7de-7f08-405b-955e-9b6676bb5426",
   "metadata": {},
   "source": [
    "### Data preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b74462-36dc-4fa7-883a-e889c545400c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3a2d8e-695b-49aa-bde3-2b630a89293b",
   "metadata": {},
   "source": [
    "# Selecting Target and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c31f62-a285-41ea-a4f4-971c6f9b84d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Pregnancies\",\t\"Glucose\",\t\"BloodPressure\",\t\"SkinThickness\",\t\"Insulin\",\t\"BMI\",\t\"DiabetesPedigreeFunction\",\t\"Age\"]\n",
    "target = [\"Outcome\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a3720e-cd8c-41f0-9e1a-9e019853ba25",
   "metadata": {},
   "source": [
    "### Here target is known and it is categorical so we need to perform supervised classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fdf3db-af03-4b5c-b48b-26f618629392",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f521f8fa-47e8-46a1-867a-cd51f320cd5e",
   "metadata": {},
   "source": [
    "# Train Test Split\n",
    "The dataset is split into training and testing sets using train_test_split(). Here, we use 80% of the data for training and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5692ec20-17e7-482a-a937-a3f2eea5d706",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0a5420-af64-43bb-8c22-0e1515fa36bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the shape of train dataset\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad9cf08-ba37-4c52-990d-b46041c88c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the shape of test dataset\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17362db3-b309-4bcf-8d77-7748a30a3af2",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750cfc5b-cdff-47f2-b916-22607e5bf78b",
   "metadata": {},
   "source": [
    "# 1. Logistic Regression\n",
    "* The model is trained on the training data using fit()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95771073-fb26-4fd6-8ce4-e638820c5820",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89e6878-0e57-47dc-93ee-222c62dbda03",
   "metadata": {},
   "source": [
    "# Prediction using Logistic Regressoin\n",
    "* We make predictions on the test set using predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f5b5c3-c357-4417-b842-d2640a833772",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_y_pred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0b423b-877a-4933-b53d-f61d4bf81672",
   "metadata": {},
   "source": [
    "# Evaulation\n",
    "* Finally, we evaluate the model using f1_score, classification report, and confusion matrix. These metrics provide insights into how well the model performs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3aa88-021f-442e-9687-625a66d5b505",
   "metadata": {},
   "source": [
    "### a. F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594ed484-0e28-44bc-838c-777ee975554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_f1_score = f1_score(y_true=y_test, y_pred=lr_model_y_pred)\n",
    "print(f\"The f1 score of logistic regression is {round(lr_model_f1_score, 3)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2703bd23-65d5-4afd-b076-48b3aff587f7",
   "metadata": {},
   "source": [
    "### b. Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee15f8d-a601-4fcd-b03b-6dae4cd8b478",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=lr_model_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e8c4cc-5d17-4a39-8954-e881e848c050",
   "metadata": {},
   "source": [
    "### c. Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cb0e8e-8c59-4a8f-af94-b3be5ea2051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(lr_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca66591-e1f7-4de6-bf87-cd896c3e436b",
   "metadata": {},
   "source": [
    "# 2. Decision Tree Classification\n",
    "* The model is trained on the training data using fit()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af6e580-50fc-4c9e-a22c-a271c8d47c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_model = DecisionTreeClassifier()\n",
    "dtc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2afae07-8786-4a46-8a97-6796bcefbe0b",
   "metadata": {},
   "source": [
    "# Prediction using decission tree classification\n",
    "* We make predictions on the test set using predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc214cd-87ea-48dc-b8c2-a0825d4a28cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_model_y_pred = dtc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de5051-ac2f-4208-a571-004a23b2d82d",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "* Finally, we evaluate the model using f1_score and classification report. These metrics provide insights into how well the model performs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7c3450-65a4-410b-8472-ed1c94b6558e",
   "metadata": {},
   "source": [
    "### a. F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463ae04e-bcdf-4d45-8d97-6e4955a861e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_model_f1_score = f1_score(y_true=y_test, y_pred=dtc_model_y_pred)\n",
    "print(f\"The f1 score of decission tree classification  is {round(dtc_model_f1_score, 3)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29538fdf-ec74-4148-b127-db352d62bacc",
   "metadata": {},
   "source": [
    "### b. Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c908fc8d-3497-4e65-a485-51ba9abb50a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=dtc_model_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70cbb5b-229d-4992-9cd7-f9fe2621df45",
   "metadata": {},
   "source": [
    "### 3. SVM\n",
    "* The model is trained on the training data using fit()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da82d1b7-c890-4fcd-bd92-798dd53be7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC()\n",
    "svc_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46da3764-8c48-432c-ab5c-869af82ced92",
   "metadata": {},
   "source": [
    "# Prediction using SVM\n",
    "* We make predictions on the test set using predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccd95c8-ffc5-419f-902f-d5628a94a2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model_y_pred = svc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42f68cd-a0ed-4d47-9af1-b19841dcc653",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "* Finally, we evaluate the model using f1_score. These metrics provide insights into how well the model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a91af50-2437-4f41-9409-9b34aa7c527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model_f1_score = f1_score(y_true=y_test, y_pred=svc_model_y_pred)\n",
    "print(f\"The f1 score of SVM is {round(svc_model_f1_score, 3)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bd7884-1351-4d8f-b92e-32c51b992d70",
   "metadata": {},
   "source": [
    "### 4. KNN\n",
    "* The model is trained on the training data using fit()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc3d6c8-8b7b-4e1b-b1e8-de1f253cb1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=3) # n_neighbours is hyperparameter to be tuned.\n",
    "knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7310e7b0-0744-4678-b135-ea182f9e1b3c",
   "metadata": {},
   "source": [
    "# prediction using KNN\n",
    "* We make predictions on the test set using predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ddd9d1-4cec-46cb-915f-e9b82e2f7cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model_y_pred = knn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2887973f-f102-40e8-990d-6aba9c0f9efd",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "* Finally, we evaluate the model using f1_score. These metrics provide insights into how well the model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77241e8e-de5e-45b9-9e56-cd8a1de8504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model_f1_score = f1_score(y_true=y_test, y_pred=knn_model_y_pred)\n",
    "print(f\"The f1 score of KNN is {round(knn_model_f1_score, 3)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dc139d-89c6-4131-8e0f-bf8f2fdfd07f",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3329a1-dc86-4540-a87d-8d1ff336426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 6)]\n",
    "max_depth = [int(x) for x in np.linspace(start = 5, stop = 30, num = 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5991b268-ade8-4754-ac58-af6a4f19a97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid = {\n",
    "    'n_estimators' : n_estimators,\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'max_depth' : max_depth,\n",
    "    'min_samples_split': [5, 10, 10, 100]\n",
    "}\n",
    "random_forest_model = RandomForestClassifier(max_depth=2, random_state=42)\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = random_forest_model, param_distributions = random_grid, cv = 3, verbose = 2,\n",
    "                  n_jobs = -1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1adf969-164d-41c4-a7f0-1b6326679de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf8642b-a318-4bba-9f4f-05c74722ab68",
   "metadata": {},
   "source": [
    "# prediction using random Forest classifier\n",
    "* We make predictions on the test set using predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6acf11e-0b8c-4543-a3cc-77c05f107288",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random_y_pred = rf_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896b3809-8600-467e-a192-96538c026d16",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "* Finally, we evaluate the model using f1_score. These metrics provide insights into how well the model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4137e41-c309-4ff4-bc98-aa68b6cd1970",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random_f1_score = f1_score(y_true=y_test, y_pred=knn_model_y_pred)\n",
    "print(f\"The f1 score of random forest classifier is {round(rf_random_f1_score, 3)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b4c07e-4055-4a59-b9b9-abf09a813222",
   "metadata": {},
   "source": [
    "# Comparison of F1 score of different algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fcc1df-2381-40ed-b63d-2504c3b89f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = {\n",
    "    \"Algorithms\": [\"LogisticRegression\",\"DecissionTresClassifier\",\"SVC\",\"KNeighborsClassifier\",\"RandomForestClassifier\"],\n",
    "    \"F1 Score\": [lr_model_f1_score,dtc_model_f1_score,svc_model_f1_score,knn_model_f1_score,rf_random_f1_score]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925c4751-21d4-423b-9237-ca10aa2b2b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_datafram = pd.DataFrame(algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9171c739-5e10-46ae-9fe8-dad7eb4ba2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_datafram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c0f997-002e-4f75-8fd7-65384274432f",
   "metadata": {},
   "source": [
    "### F1 score of logistic regression is high among all algorithms. Therefore, LogisticRegression is best for this data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8392d1e-28c3-4131-8a92-cf08e35979d4",
   "metadata": {},
   "source": [
    "# Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e66566f-8e59-4f7a-9fee-5e44d581e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"final_model.pickle\",\"bw\") as file:\n",
    "    pickle.dump(lr_model, file) # serializing logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b844fa4-4e5b-41cf-89b7-4e5cf16fdae2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
